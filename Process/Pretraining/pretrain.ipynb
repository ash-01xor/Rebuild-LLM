{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up GPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,\n",
    "                 context_length,dropout,\n",
    "                 num_heads, qkv_bias=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out,d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length,context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        b, num_tokens , d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # Splitting the matrix by adding num_heads\n",
    "        keys = keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        values = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "\n",
    "\n",
    "        # Converting the shape\n",
    "        # b,num_tokens,num_heads,head_dim = b,num_heads,num_tokens,head_dim\n",
    "        # crucial for aligning the keys and values in multiple heads\n",
    "        keys = keys.transpose(1,2) \n",
    "        queries = queries.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "\n",
    "        attention_scores = queries @ keys.transpose(2,3) # dot product for each head\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / keys.shape[-1]**0.5 , dim = -1\n",
    "        )\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # b , num_token , n_heads , head_dim\n",
    "        context_vectors = (attention_weights @ values).transpose(1,2) \n",
    "\n",
    "        # combines the heads \n",
    "        context_vectors = context_vectors.contiguous().view(\n",
    "            b,num_tokens,self.d_out\n",
    "        )\n",
    "        context_vectors = self.out_proj(context_vectors)\n",
    "        return context_vectors\n",
    "    \n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out= cfg[\"emb_dim\"],\n",
    "            context_length= cfg[\"context_length\"],\n",
    "            num_heads= cfg[\"n_heads\"],\n",
    "            dropout= cfg[\"drop_rate\"],\n",
    "            qkv_bias= cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])   \n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + residual\n",
    "\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)  \n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + residual\n",
    "        return x\n",
    "    \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False)\n",
    "        norm_x = (x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return 0.5*x*(1+torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
    "            (x+0.044715+torch.pow(x,3))\n",
    "        ))\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],cfg[\"emb_dim\"]*4),\n",
    "            GELU(),\n",
    "            nn.Linear(cfg[\"emb_dim\"]*4,cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for  _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,in_idx):\n",
    "        batch_size , seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len,device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:The sky is Schnewhy ripple gratificationcularSizecampaign lies suggestions meet\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def generate_text(model,idx,max_new_tokens,context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:] \n",
    "        probas = torch.softmax(logits,dim=-1)\n",
    "        idx_next = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "        idx = torch.cat((idx,idx_next),dim=-1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"The sky is\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(f\"Output text:{token_ids_to_text(token_ids,tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cells we have setup the architecture of the model and also the function for generation text. We can see that there is incoherant text being generated by the model. This is because the model is not trained on any data. We will now train the model on the data and then generate text using the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating loss for text generation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits,dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text generation process can be simplified as further:\n",
    "- Given a large corpus of vocabulary , we creating a mapping of the vocabulary to token IDs\n",
    "- we obtain a n-dimensional probability vector for each input token as specified in the configs\n",
    "- Identify the index position with highest probability values in each row\n",
    "- Obtain all the predicted token IDs as the index position with highest probability\n",
    "- Map the index position back to text via an inverse vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[24851],\n",
      "         [  406],\n",
      "         [40115]],\n",
      "\n",
      "        [[29716],\n",
      "         [40825],\n",
      "         [37022]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: etti L HO\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model hasn't yet been trained on vocabulary we can see the outputs of not good quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.3679e-06, 2.1341e-05, 1.0216e-05])\n",
      "Text 2: tensor([1.2381e-05, 3.0002e-05, 6.1751e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.3412, -10.7549, -11.4916, -11.2994, -10.4142, -11.9950])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.3827)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3827)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3827)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(87790.6641)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross entropy loss is the difference between actual and predicted probability distribution of the model.\n",
    "- Perplexity is just the exponential of cross entropy\n",
    "- It also refers to the probability distribution predicted by the model and how well it matches the distribution of words present in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model of small dataset:\n",
    "\n",
    "Trying to train on the model on already existant dataset which was using in text-preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../Text-processing-basic/data.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of characters: 20479\n",
      "total number of tokens:5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"total number of characters: {total_characters}\")\n",
    "print(f\"total number of tokens:{total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diving the dataset into training and validation4\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18431, 2048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx]\n",
    "    \n",
    "\n",
    "def create_dataloaderv1(txt,batch_size=4,max_length=256,\n",
    "                      stride=128,shuffle=True,drop_last=True,\n",
    "                      num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(txt,tokenizer,max_length,stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloaderv1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_length = GPT_CONFIG[\"context_length\"],\n",
    "    stride = GPT_CONFIG[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloaderv1(\n",
    "    val_data,\n",
    "    batch_size = 2,\n",
    "    max_length = GPT_CONFIG[\"context_length\"],\n",
    "    stride = GPT_CONFIG[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader data sizes\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Validation loader data sizes\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train loader data sizes\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(f\"Validation loader data sizes\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_batch(input_batch,target_batch,model,device):\n",
    "    \"\"\"\n",
    "    Function to calculate the loss for a single batch\n",
    "    \"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1),target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calculate_loss_batch(\n",
    "                input_batch,target_batch,model,device\n",
    "            )\n",
    "            total_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:11.009906768798828\n",
      "Validation loss:11.048162460327148\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad(): #this is for disabling the gradient calculation\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "print(f\"Training loss:{train_loss}\")\n",
    "print(f\"Validation loss:{val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model:\n",
    "\n",
    "The process of training the model is as follows:\n",
    "- iterate over the training epochs\n",
    "- iterate over the batches for each epoch\n",
    "- reset the gradients of loss from previous batch\n",
    "- calculate loss for current batch\n",
    "- backward pass to calculate loss gradients\n",
    "- update the model weights using loss gradients\n",
    "Inspect\n",
    "- the losses in training and validation set\n",
    "- sample text to see the quality of generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,train_loader,val_loader,\n",
    "                       optimizer,device,num_epochs,eval_freq,\n",
    "                       eval_iter,start_context,tokenizer):\n",
    "    train_losses , val_losses , track_tokens_seen = [],[],[]\n",
    "    tokens_seen , global_step = 0,-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch,target_batch in train_loader:\n",
    "            optimizer.zero_grad() #resets loss gradients in prev batch\n",
    "            loss = calculate_loss_batch(\n",
    "                input_batch,target_batch,model,device\n",
    "            )\n",
    "            loss.backward() # calculate loss gradients\n",
    "            optimizer.step() #update model weights\n",
    "            tokens_seen += input_batch.numel() \n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss , val_loss = evaluate_model(\n",
    "                    model,train_loader,val_loader,device,eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch:{epoch+1} (Step:{global_step:06d}): \"\n",
    "                      f\"Train loss:{train_loss:.4f}, \"\n",
    "                      f\"Validation loss:{val_loss:.4f}\")\n",
    "                \n",
    "        generate_print_sample(\n",
    "            model,tokenizer,device,start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval() #dropout is disabled\n",
    "    with torch.no_grad(): #disable gradient tracking as  it not required during eval\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_print_sample(model,tokenizer,device,start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text(model,idx=encoded,\n",
    "                                  max_new_tokens=50,\n",
    "                                  context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids,tokenizer)\n",
    "    print(f\"Generated text:\\n{decoded_text}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 (Step:000000): Train loss:10.5723, Validation loss:10.6358\n",
      "Epoch:1 (Step:000005): Train loss:9.2652, Validation loss:9.4483\n",
      "Generated text:\n",
      "The whole world is,,,, the,, the,,,, the, the,,, the the, the,,, the,, the,,,, the,,, the, the, the, the, the,, the,\n",
      "Epoch:2 (Step:000010): Train loss:8.6954, Validation loss:8.9277\n",
      "Epoch:2 (Step:000015): Train loss:8.1692, Validation loss:8.4476\n",
      "Generated text:\n",
      "The whole world is the, the, the, the, the, the, the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:3 (Step:000020): Train loss:7.6541, Validation loss:8.0169\n",
      "Epoch:3 (Step:000025): Train loss:7.1809, Validation loss:7.6020\n",
      "Generated text:\n",
      "The whole world is, the, the, the, the, the, the the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:4 (Step:000030): Train loss:6.7261, Validation loss:7.2775\n",
      "Epoch:4 (Step:000035): Train loss:6.2174, Validation loss:7.0114\n",
      "Generated text:\n",
      "The whole world is the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:5 (Step:000040): Train loss:5.8261, Validation loss:6.8582\n",
      "Generated text:\n",
      "The whole world is the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\" I had the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"--I, I had the, I had the I had the I had the the--I, and\n",
      "Epoch:6 (Step:000045): Train loss:5.4446, Validation loss:6.7269\n",
      "Epoch:6 (Step:000050): Train loss:5.1034, Validation loss:6.5778\n",
      "Generated text:\n",
      "The whole world is the of the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:7 (Step:000055): Train loss:4.6632, Validation loss:6.5370\n",
      "Epoch:7 (Step:000060): Train loss:4.3240, Validation loss:6.4581\n",
      "Generated text:\n",
      "The whole world is the of the.\n",
      "\n",
      "\n",
      "\"I--I--as the.\n",
      "\"I was the a, the, I had the to the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I of the, and I had been his I had\n",
      "Epoch:8 (Step:000065): Train loss:3.9930, Validation loss:6.4382\n",
      "Epoch:8 (Step:000070): Train loss:3.7443, Validation loss:6.3370\n",
      "Generated text:\n",
      "The whole world is the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"--as the.\n",
      "\"I--and by a to me.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\" I had the donkey. I had been his.\n",
      "\n",
      "Epoch:9 (Step:000075): Train loss:3.5072, Validation loss:6.2915\n",
      "Epoch:9 (Step:000080): Train loss:3.1109, Validation loss:6.3152\n",
      "Generated text:\n",
      "The whole world is the I was not that I felt--I--I of the.\n",
      "\n",
      "\"I was a little that the\n",
      "\n",
      "\n",
      "\n",
      "\"--as, and his pictures.\n",
      "\n",
      "\n",
      "\"I had the donkey. \"There--I was.\n",
      "Epoch:10 (Step:000085): Train loss:2.8856, Validation loss:6.3731\n",
      "Generated text:\n",
      "The whole world is the I was one of the picture--I felt, and he had been in the: \"--as, in the I had to see a smile, on a _, as his pictures--as, the, and \"strong.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses , val_losses, tokens_seen = train_model_simple(\n",
    "    model,train_loader,val_loader,optimizer,device,\n",
    "    num_epochs=num_epochs,eval_freq=5,eval_iter=5,\n",
    "    start_context=\"The whole world is\",tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visuvalize results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses): \n",
    "    train_losses = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in train_losses]\n",
    "    val_losses = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in val_losses]\n",
    "    print(f\"Train_losses:{train_losses}\")\n",
    "    print(f\"Validation losses:{val_losses}\")\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_losses:[10.572341918945312, 9.265179634094238, 8.695446014404297, 8.169197082519531, 7.654104709625244, 7.180861949920654, 6.726071834564209, 6.217419624328613, 5.8261332511901855, 5.444582939147949, 5.103413105010986, 4.663182735443115, 4.324002265930176, 3.992976427078247, 3.7443084716796875, 3.5071542263031006, 3.110865354537964, 2.8856091499328613]\n",
      "Validation losses:[10.635773658752441, 9.448346138000488, 8.927709579467773, 8.447583198547363, 8.016867637634277, 7.602049350738525, 7.277523040771484, 7.011449813842773, 6.858166217803955, 6.7268877029418945, 6.5777668952941895, 6.536977291107178, 6.458137512207031, 6.43817663192749, 6.336983680725098, 6.291548252105713, 6.315249919891357, 6.373128414154053]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference:\n",
    "- The training loss is way lower than the validation loss indicating the model is overfitting.\n",
    "- This might mostly be due to the small dataset used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text using various decoding methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval() #model is made to not utilize dropout and other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      "The whole world is the I was one of the picture--I felt, and he had been in the: \"--as, in the I\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"The whole world is\", tokenizer),\n",
    "    max_new_tokens = 25,\n",
    "    context_size = GPT_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text:\\n{token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference:\n",
    "- The above cell returns the same generated text every time we run it. The words generated after input text represents the words which has the highest probability. Thus making the process entirely deterministic\n",
    "\n",
    "\n",
    "We can now try to randomize the process of generating text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'closer', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "#assuming a fixed small size vocab to experiment\n",
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v:k for k,v in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token ID Greedy method: 3\n",
      "Next token ID multinomial: 3\n"
     ]
    }
   ],
   "source": [
    "#assuming random logits value for the vocab present\n",
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "\n",
    "#probabilities calculation\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "greedy_next_token_id = torch.argmax(probas).item()\n",
    "multinomial_next_token_id = torch.multinomial(probas, 1).item()\n",
    "print(f\"Next token ID Greedy method: {greedy_next_token_id}\")\n",
    "print(f\"Next token ID multinomial: {multinomial_next_token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- while both the tokens generated are same the catch is that , with multinomial function the sampling of words from the vocab is done in a probabilistic manner i.e not just based on the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer:71\n",
      "every:2\n",
      "effort:0\n",
      "forward:544\n",
      "inches:2\n",
      "moves:1\n",
      "pizza:0\n",
      "toward:376\n",
      "you:4\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "    for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{inverse_vocab[i]}:{freq}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using temperature scaling to generate\n",
    "def softmax_temperature(logits,temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1.,0.1,5]\n",
    "scaled_probas = [softmax_temperature(next_token_logits,temperature)\n",
    "                 for temperature in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer:0\n",
      "every:0\n",
      "effort:0\n",
      "forward:992\n",
      "inches:0\n",
      "moves:0\n",
      "pizza:0\n",
      "toward:8\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer:153\n",
      "every:68\n",
      "effort:55\n",
      "forward:223\n",
      "inches:102\n",
      "moves:50\n",
      "pizza:43\n",
      "toward:218\n",
      "you:88\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the temperature is set to 5, then we can see the model sampling to go haywire compared to when the temperature is set to 0.1 where the effect of torch.argmax leads to more deterministic result of sampling a particular word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-k sampling:\n",
    "\n",
    "The idea is to extend from the previous method , where we were able to generate diverse tokens. However one downside of such a method is the utter nonsense that it can produce. Thus top-k sampling helps in reducing that.\n",
    "We get to decrease the utter randomness of selecting a particular token by reducing the limit of tokens to be considered for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logits:tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions:tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits , top_pos = torch.topk(next_token_logits,top_k)\n",
    "print(f\"Top Logits:{top_logits}\")\n",
    "print(f\"Top Positions:{top_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float(\"-inf\")),\n",
    "    other = next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits,dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,idx,max_new_tokens ,context_size,temperature=0.0,\n",
    "             top_k= None,eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:] \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits , _ = torch.topk(logits,top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(\n",
    "                logits<min_val,\n",
    "                torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx,idx_next),dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "Every effort moves into circulation that, you that the with a a little, so--as\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "token_ids = generate(\n",
    "    model,\n",
    "    idx = text_to_token_ids(\"Every effort moves\",tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size= GPT_CONFIG[\"context_length\"],\n",
    "    top_k = 25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(f\"Output:\\n{token_ids_to_text(token_ids,tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and saving the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\",map_location=device,weights_only=True))\n",
    "model.eval(); #this switches the model to eval model disables dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/1135469871.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 08:12:39.835530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736563359.899910    6151 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736563359.918013    6151 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-11 08:12:40.069068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_load_gpt2(model_size,models_dir):\n",
    "    allowed_sizes = (\"124M\",\"335M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "    \n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path, backup_url)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def download_file(url, destination, backup_url=None):\n",
    "    def _attempt_download(download_url):\n",
    "        with urllib.request.urlopen(download_url) as response:\n",
    "            # Get the total file size from headers, defaulting to 0 if not present\n",
    "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "            # Check if file exists and has the same size\n",
    "            if os.path.exists(destination):\n",
    "                file_size_local = os.path.getsize(destination)\n",
    "                if file_size == file_size_local:\n",
    "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                    return True  # Indicate success without re-downloading\n",
    "\n",
    "            block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "            # Initialize the progress bar with total file size\n",
    "            progress_bar_description = os.path.basename(download_url)\n",
    "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "                with open(destination, \"wb\") as file:\n",
    "                    while True:\n",
    "                        chunk = response.read(block_size)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))\n",
    "            return True\n",
    "\n",
    "    try:\n",
    "        if _attempt_download(url):\n",
    "            return\n",
    "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
    "        if backup_url is not None:\n",
    "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
    "            try:\n",
    "                if _attempt_download(backup_url):\n",
    "                    return\n",
    "            except urllib.error.HTTPError:\n",
    "                pass\n",
    "\n",
    "        # If we reach here, both attempts have failed\n",
    "        error_message = (\n",
    "            f\"Failed to download from both primary URL ({url})\")\n",
    "        print(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings , params = download_load_gpt2(\n",
    "    model_size=\"124M\",models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Params explore:dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Settings:{settings}\")\n",
    "print(f\"Params explore:{params.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "model_name = \"gpt2-small (124M)\" \n",
    "NEW_CONFIG = GPT_CONFIG.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: What is life all for you? Well, as the news story had it just some good people from all kinds of \"craze up all\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_ids = generate(\n",
    "    model = gpt,\n",
    "    idx = text_to_token_ids(\"What is life all\", tokenizer).to(device),\n",
    "    max_new_tokens = 25,\n",
    "    context_size = NEW_CONFIG[\"context_length\"],\n",
    "    top_k = 50,\n",
    "    temperature= 1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
